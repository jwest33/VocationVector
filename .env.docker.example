# Docker Environment Configuration for VocationVector

# Application settings
APP_ENVIRONMENT=production
FLASK_ENV=production

# LLM Model Configuration
# Path to the directory containing your GGUF model file on the host machine
LLM_MODEL_PATH=C:\models

# Name of the GGUF model file
LLM_MODEL_NAME=Qwen3-4B-Instruct-2507-F16.gguf

# LLM Server Configuration
# Context size: Qwen3-4B supports up to 32K context window
LLM_CTX_SIZE=32768
LLM_N_THREADS=4
LLM_MEMORY_LIMIT=8G
LLM_MEMORY_RESERVATION=4G

# Port mappings (if you need to change defaults)
# APP_PORT=5000
# LLM_SERVER_PORT=8000
